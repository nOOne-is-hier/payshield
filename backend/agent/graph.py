from __future__ import annotations
import os
import time
from typing import Any, Dict, Optional, List

from pydantic import BaseModel
from langgraph.graph import StateGraph, END

# íˆ´: httpxë¡œ FastAPI í˜¸ì¶œ (ì´ë¯¸ êµ¬í˜„í•´ë‘” agent/tools.py ì‚¬ìš©)
from agent.tools import (
    get_metrics,
    set_threshold,
    trigger_retrain,
    send_sms,
    post_dashboard_summary,
    feeder_start as tl_feeder_start,
    feeder_inject_drift as tl_feeder_inject,
    feeder_stop,
)


DEMO = os.getenv("AIOPS_DEMO", "1") == "1"
AIOPS_DEMO = os.getenv("AIOPS_DEMO", "0") == "1"  # ë°ëª¨ì—ì„œë§Œ ë“œë¦¬í”„íŠ¸ ì£¼ì… í—ˆìš©
_FEEDER_STARTED = False  # í”„ë¡œì„¸ìŠ¤ ë‚´ 1íšŒ ë³´ì¥
_LAST_DRIFT_AT = 0.0
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
assert OPENAI_API_KEY, "OPENAI_API_KEY missing"


# (NEW) OpenAI LLM - ìš”ì•½ ê°•í™”ìš©
# í™˜ê²½ë³€ìˆ˜ OPENAI_API_KEY í•„ìš”
LLM_ENABLED = os.getenv("AIOPS_LLM_ENABLED", "1") == "1"
LLM_MODEL = os.getenv("AIOPS_LLM_MODEL", "gpt-4o-mini")
RICH_SUMMARY = os.getenv("AIOPS_SUMMARY_RICH", "1") == "1"
if LLM_ENABLED:
    try:
        from langchain_openai import ChatOpenAI
        from langchain_core.messages import SystemMessage, HumanMessage

        _llm = ChatOpenAI(model=LLM_MODEL, temperature=0)
    except Exception as _e:
        # LLM ë¡œë”© ì‹¤íŒ¨ ì‹œ ìë™ ë¹„í™œì„±í™”
        print("[graph] LLM init failed -> fallback to rule-only:", repr(_e))
        LLM_ENABLED = False


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ìƒíƒœ ì •ì˜
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
class AgentState(BaseModel):
    metrics: Optional[Dict[str, Any]] = None
    summary: Optional[str] = None
    actions: List[Dict[str, Any]] = []
    hi_count: int = 0
    last_threshold_change_at: float = 0.0
    last_retrain_at: float = 0.0


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ë…¸ë“œ 1) ìˆ˜ì§‘: /metrics í˜¸ì¶œ + hi_count ê°±ì‹ 
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def ingest(state: AgentState) -> AgentState:
    m = get_metrics.invoke({"cur_win": 300})  # dict ë°˜í™˜
    drift = m.get("drift", []) if isinstance(m, dict) else []
    high = any(d.get("level") == "high" for d in drift)
    state.hi_count = state.hi_count + 1 if high else 0
    state.metrics = m
    return state


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ë…¸ë“œ 2) ìš”ì•½: ìš´ì˜ìê°€ ë³´ê¸° ì‰¬ìš´ í•œ ì¤„ ìš”ì•½ ìƒì„±
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def summarize(state: AgentState) -> AgentState:
    m = state.metrics or {}
    drift = m.get("drift", [])
    amount_psi = next(
        (d.get("psi", 0.0) for d in drift if d.get("feature") == "amount"), 0.0
    )
    score_psi = next(
        (d.get("psi", 0.0) for d in drift if d.get("feature") == "score"), 0.0
    )

    sstats = m.get("score_stats", {}) or {}
    score_p95 = sstats.get("p95", 0.0)
    d_score_p95 = sstats.get("delta_p95", 0.0)
    lat_p95_ms = m.get("latency_p95_ms", 0.0)

    near = sstats.get("near_rate", 0.0)
    tail = sstats.get("tail_rate", 0.0)
    ar = m.get("anomaly_rate", 0.0)
    state.summary = (
        f"win={m.get('window_size')} thr={m.get('threshold')} "
        f"AR={ar*100:.2f}% "
        f"amount.psi={amount_psi:.2f} score.psi={score_psi:.2f} "
        f"score.p95={score_p95:.3f} Î”score.p95={d_score_p95:.3f} near={near:.3f} tail={tail:.3f} "
        f"lat.p95_ms={lat_p95_ms:.0f} hi_count={state.hi_count}"
    )
    post_dashboard_summary.invoke({"text": state.summary, "payload": m})
    return state


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# (NEW) ë…¸ë“œ 2.5) LLM ìš”ì•½ ê°•í™”: ìš´ì˜ì ì¹œí™” 2~3ì¤„ ìì—°ì–´ ë³´ê°•
#  - ì•¡ì…˜ì€ ìˆ˜í–‰í•˜ì§€ ì•ŠìŒ(íˆ´ì½œ ì—†ìŒ)
#  - ì‹¤íŒ¨í•´ë„ íŒŒì´í”„ë¼ì¸ì€ ê³„ì† ì§„í–‰
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def llm_summarize(state: AgentState) -> AgentState:
    if not LLM_ENABLED:
        return state

    try:
        m = state.metrics or {}
        if RICH_SUMMARY:
            sys = (
                "ë„ˆëŠ” AIOps ë“œë¦¬í”„íŠ¸ ìš”ì•½ ì‘ì„±ìë‹¤. ì…ë ¥(/metrics JSON, hi_count)ì„ ë°”íƒ•ìœ¼ë¡œ "
                "**ë¶ˆë¦¿ 4~6ì¤„ì˜ ë¦¬ì¹˜ ìš”ì•½**ì„ í•œêµ­ì–´ë¡œ ì¶œë ¥í•˜ë¼. ë§ˆí¬ë‹¤ìš´/ì´ëª¨ì§€ í—ˆìš©. ì•¡ì…˜ì€ ìˆ˜í–‰í•˜ì§€ ë§ê³  ìš”ì•½ë§Œ ì¶œë ¥.\n"
                "- 1ì¤„: ìƒíƒœ ë±ƒì§€(âœ… ì •ìƒ/âš ï¸ ê²½ê³ /ğŸš¨ ê³ ìœ„í—˜) + í•œì¤„ ì´í‰\n"
                "- 2ì¤„: í•µì‹¬ ìˆ˜ì¹˜: threshold, window_size, anomaly_rate(%), latency_p95_ms(ms)\n"
                "- 3ì¤„: PSI í‘œ(ì´ëª¨ì§€ ë ˆë²¨): amount.psi, score.psi (ì˜ˆ: amount.psi=0.68 âš ï¸, score.psi=2.26 ğŸš¨)\n"
                "- 4ì¤„: ì ìˆ˜ ë¶„í¬: score.p95, Î”score.p95, near_rate, tail_rate (ì¦ê° í™”ì‚´í‘œ â†‘â†“â†’)\n"
                "- 5ì¤„: ë³€í™” ì›ì¸ ê°€ì„¤ 1ì¤„ (ì˜ˆ: ìƒìœ„ ê¼¬ë¦¬ ë¹„ëŒ€/ìŠ¤íŒŒì´í¬/ì£¼ê¸°ì„± ë“±)\n"
                "- 6ì¤„: ê¶Œê³  1ì¤„ (ì˜ˆ: ì„ê³„ ë³´ì • ìœ ì§€/ë ˆí¼ëŸ°ìŠ¤ ì¬ì„¤ì • ê²€í† /ì¬í•™ìŠµ ì™„ë£Œ í™•ì¸ ë“±)\n"
                "ìˆ«ìëŠ” ì†Œìˆ˜ 2ìë¦¬, í¼ì„¼íŠ¸ëŠ” Ã—100 í›„ ì†Œìˆ˜ 2ìë¦¬. ë„ˆë¬´ ê¸¸ë©´ 12ì¤„ ì´ë‚´."
            )
        else:
            sys = (
                "ë„ˆëŠ” AIOps ë“œë¦¬í”„íŠ¸ ìš”ì•½ ì‘ì„±ìë‹¤. 2~3ì¤„ì˜ ê°„ê²° ìš”ì•½ë§Œ ì¶œë ¥í•˜ë¼. "
                "amount.psi, score.psi, score_stats.p95/Î”p95/near_rate, threshold, window_size, latency_p95_ms í¬í•¨."
            )
        user = "state.hi_count=" + str(state.hi_count) + "\n" "metrics JSON:\n" + str(m)
        msgs = [SystemMessage(content=sys), HumanMessage(content=user)]
        ai = _llm.invoke(msgs)
        if ai and getattr(ai, "content", None):
            llm_txt = ai.content.strip()
            # ë¦¬ì¹˜ ëª¨ë“œë©´ ì¤„ë°”ê¿ˆ ìœ ì§€, ì•„ë‹ˆë©´ í•œ ì¤„ë¡œ ì¶•ì•½
            if not RICH_SUMMARY:
                llm_txt = llm_txt.replace("\n", " ")
            state.summary = (state.summary or "") + (
                f"\n{llm_txt}" if RICH_SUMMARY else f" | LLM: {llm_txt}"
            )
            post_dashboard_summary.invoke({"text": state.summary})
    except Exception as e:
        # LLM ì‹¤íŒ¨ëŠ” ë¬´ì‹œí•˜ê³  ë£° ê³„ì†
        print("[graph] llm_summarize error:", repr(e))
    return state


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ë…¸ë“œ 3) ê²°ì • & ì‹¤í–‰: ì„ê³—ê°’ ì¡°ì • / ì¬í•™ìŠµ / SMS
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def decide_and_act(state: AgentState) -> AgentState:
    state.actions = []  # ì´ë²ˆ í„´ì˜ ì‹¤í–‰ ë‚´ì—­ ê¸°ë¡

    m = state.metrics or {}
    drift = m.get("drift", [])
    thr = float(m.get("threshold", 0.70))
    now = time.time()

    amount_psi = next(
        (d.get("psi", 0.0) for d in drift if d.get("feature") == "amount"), 0.0
    )
    score_psi = next(
        (d.get("psi", 0.0) for d in drift if d.get("feature") == "score"), 0.0
    )
    psi_high = (amount_psi >= 0.4) or (score_psi >= 0.4)

    # 1) PSI highë©´ ì„ê³—ê°’ +0.02 (ì¿¨ë‹¤ìš´ 300s)
    thr_cool_ok = (now - state.last_threshold_change_at) >= 300.0
    if psi_high and thr_cool_ok:
        new_thr = min(thr + 0.02, 0.85)
        if new_thr > thr:
            set_threshold.invoke({"new_threshold": new_thr})
            state.last_threshold_change_at = now
            state.actions.append(
                {"type": "THRESHOLD", "value": new_thr, "reason": "psi_high"}
            )
            post_dashboard_summary.invoke(
                {"text": f"Threshold {thr:.2f} â†’ {new_thr:.2f} (PSI high)"}
            )

    # 2) PSI high 3íšŒ ì—°ì†ì´ë©´ ì¬í•™ìŠµ + SMS (ì¿¨ë‹¤ìš´ 600s)
    rt_cool_ok = (now - state.last_retrain_at) >= 600.0
    if psi_high and state.hi_count >= 3 and rt_cool_ok:
        trigger_retrain.invoke({"reason": "psi_high_persistent"})
        send_sms.invoke(
            {
                "to": "+82-10-0000-0000",
                "message": "[Fraud] PSI high persists; retrain triggered.",
            }
        )
        # ğŸ”» ì‹œì—°ìš©: ì¬í•™ìŠµê³¼ ë™ì‹œì— feeder ì •ì§€
        if DEMO:
            try:
                feeder_stop.invoke({})
                state.actions.append({"type": "FEEDER_STOP", "reason": "retrain"})
                post_dashboard_summary.invoke(
                    {"text": "[FEEDER] stopped (due to retrain)"}
                )
            except Exception as e:
                post_dashboard_summary.invoke(
                    {"text": f"[FEEDER] stop failed: {repr(e)}"}
                )

        state.last_retrain_at = now
        state.actions.append({"type": "RETRAIN", "reason": "psi_high_persistent"})

    return state


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# (NEW) ë…¸ë“œ 0) feeder ì œì–´: ref ì—†ì„ ë•Œ ì •ìƒ í”¼ë“œ 1íšŒ, ë°ëª¨ì¼ ë•Œë§Œ ë“œë¦¬í”„íŠ¸ ì£¼ì…
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def feeder_control(state: AgentState) -> AgentState:
    global _FEEDER_STARTED, _LAST_DRIFT_AT
    m = state.metrics or {}

    # 0) ref ì—†ê³  í‘œë³¸ ë¶€ì¡±/AR ë‚®ìœ¼ë©´ ì •ìƒ í”¼ë“œ 1íšŒ ì‹œì‘
    if not _FEEDER_STARTED:
        ref_set = int(m.get("ref_set_at") or 0)
        if (ref_set == 0) and (m.get("window_size", 0) < 150):
            try:
                tl_feeder_start.invoke({})
                _FEEDER_STARTED = True
                post_dashboard_summary.invoke(
                    {"text": "[FEEDER] normal feed started (auto)"}
                )
            except Exception as e:
                print("[feeder_control] start_normal failed:", repr(e))

    # 1) (ì˜µì…˜) ë°ëª¨ ëª¨ë“œì—ì„œë§Œ ë“œë¦¬í”„íŠ¸ ê°„í— ì£¼ì… (ê³¼ë„ í˜¸ì¶œ ë°©ì§€)
    if AIOPS_DEMO:
        now = time.time()
        psi_high = False
        for d in m.get("drift", []):
            if d.get("level") == "high":
                psi_high = True
                break
        # ë°ëª¨ ì²´í—˜ìš©: í•œë™ì•ˆ ì ì í•˜ë©´ 40ì´ˆ ì£¼ì…
        if (not psi_high) and (now - _LAST_DRIFT_AT) > 180:
            try:
                tl_feeder_inject.invoke({"seconds": 40.0})
                _LAST_DRIFT_AT = now
                post_dashboard_summary.invoke(
                    {"text": "[FEEDER] drift injected 40s (demo)"}
                )
            except Exception as e:
                print("[feeder_control] inject_drift failed:", repr(e))

    return state


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ê·¸ë˜í”„ ì»´íŒŒì¼
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def build_graph():
    sg = StateGraph(AgentState)
    sg.add_node("ingest", ingest)
    sg.add_node("feeder_control", feeder_control)  # â† ì¶”ê°€
    sg.add_node("summarize", summarize)
    sg.add_node("llm_summarize", llm_summarize)
    sg.add_node("decide_and_act", decide_and_act)

    sg.set_entry_point("ingest")
    sg.add_edge("ingest", "feeder_control")  # ingest ë‹¤ìŒ feeder ì œì–´
    sg.add_edge("feeder_control", "summarize")
    sg.add_edge("summarize", "llm_summarize")
    sg.add_edge("llm_summarize", "decide_and_act")
    sg.add_edge("decide_and_act", END)
    return sg.compile()


graph = build_graph()
